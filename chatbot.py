from langchain_groq import ChatGroq
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory

def get_response(text, api_key):
    """
    Generate a response from the language model with memory support.

    Args:
        text (str): The user input text to process.
        api_key (str): API key for accessing the language model.

    Returns:
        str: The response generated by the AI model.
    """
    # Initialize memory to keep track of the conversation history
    history = StreamlitChatMessageHistory(key="chat_messages")
    
    # Define the prompt template for the chatbot conversation
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "You are an advanced AI chatbot capable of understanding and responding in Urdu. Your primary goal is to assist users with accurate and helpful information, answer their questions, and address their needs effectively. Ensure your responses are clear, contextually relevant, and polite. Always seek to provide detailed and precise answers based on the user's queries. Maintain a professional and supportive tone throughout the conversation, and strive to improve the user's experience by adapting to their input and preferences."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"),
        ]
    )

    # Initialize the language model with specified parameters
    chat_model = ChatGroq(
        model="llama-3.1-70b-versatile",
        api_key=api_key,  
        temperature=0,  
        max_tokens=None,  
        timeout=None,   
        max_retries=2, 
    )

    # Create a chain with the prompt and language model
    chain = prompt | chat_model

    # Create a runnable chain with message history support
    chain_with_history = RunnableWithMessageHistory(
        chain,
        lambda session_id: history,  
        input_messages_key="question",  
        history_messages_key="history",  
    )

    # Add the user's message to the history
    history.add_user_message(text)
    
    # Get the AI response from the language model using the chain with history
    response = chain_with_history.invoke({"question": text}, {"configurable": {"session_id": "any"}})
    
    # Add the AI response to the history
    history.add_ai_message(response.content)
    
    # Return the response content from the AI model
    return response.content
